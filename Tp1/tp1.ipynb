{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10596614",
   "metadata": {},
   "source": [
    "# VpC - Trabajo Práctico 1\n",
    "\n",
    "Algoritmo White Patch - Implementación de diferentes versiones para corrección de color\n",
    "Análisis de Histogramas - Evaluación de histogramas como característica para clasificación de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b08b6c0",
   "metadata": {},
   "source": [
    "## 1. Algoritmo White Patch - Versión Simple\n",
    "\n",
    "Se desarrolló una versión básica del algoritmo que ofreció resultados satisfactorios en las imágenes test_*.jpg.\n",
    "El algoritmo White Patch asume que el píxel más brillante de cada canal debería ser blanco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch(img: np.ndarray):\n",
    "    img_float = img.astype(np.float32)\n",
    "    max_channel_value = np.max(img_float, axis=(0, 1))\n",
    "    cantidad_de_desviaciones = 1.5\n",
    "    correction_factors = np.ones(3, dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(max_channel_value)):\n",
    "        if max_channel_value[i] < 1:\n",
    "            correction_factors[i] = 255 / (np.mean(img_float[:, :, i]) - \n",
    "                                         cantidad_de_desviaciones*np.std(img_float[:, :, i]))\n",
    "        elif max_channel_value[i] > 254:\n",
    "            correction_factors[i] = 255 / (np.mean(img_float[:, :, i]) + \n",
    "                                         cantidad_de_desviaciones*np.std(img_float[:, :, i]))\n",
    "        else:\n",
    "            correction_factors[i] = 255.0 / np.clip(max_channel_value[i], 1, 254)\n",
    "\n",
    "    corrected_img = img_float * correction_factors\n",
    "    corrected_img = np.clip(corrected_img, 0, 255).astype(np.uint8)\n",
    "    return corrected_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c92ff44",
   "metadata": {},
   "source": [
    "## 2. Algoritmo White Patch Inteligente\n",
    "\n",
    "Implementa diferentes estrategias para mejores resultados.\n",
    "La versión inicial no contemplaba situaciones límite, como la presencia de píxeles con valores 0 o 255. Por ello se creó una segunda variante que sí considera estos extremos. Estas dos primeras iteraciones funcionaron bien sobre las imágenes wp_*.jpg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff13847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch_intelligent(img: np.ndarray, method='percentile', percentile=99.5):\n",
    "    img_float = img.astype(np.float32)\n",
    "\n",
    "    if method == 'percentile':\n",
    "        reference_values = np.percentile(img_float, percentile, axis=(0, 1))\n",
    "\n",
    "    elif method == 'edge_based':\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        edges_dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "\n",
    "        reference_values = []\n",
    "        for i in range(3):\n",
    "            channel_values = img_float[:, :, i][edges_dilated > 0]\n",
    "            if len(channel_values) > 0:\n",
    "                reference_values.append(np.percentile(channel_values, 95))\n",
    "            else:\n",
    "                reference_values.append(np.max(img_float[:, :, i]))\n",
    "        reference_values = np.array(reference_values)\n",
    "\n",
    "    elif method == 'iterative':\n",
    "        reference_values = np.zeros(3)\n",
    "        for i in range(3):\n",
    "            channel = img_float[:, :, i].copy()\n",
    "            saturated_pixels = channel[channel > 240]\n",
    "\n",
    "            if len(saturated_pixels) == 0:\n",
    "                reference_values[i] = np.max(channel)\n",
    "            else:\n",
    "                for iteration in range(3):\n",
    "                    valid_pixels = channel[channel < 240]\n",
    "                    if len(valid_pixels) > 0:\n",
    "                        threshold = np.percentile(valid_pixels, 98)\n",
    "                        channel = valid_pixels[valid_pixels <= threshold]\n",
    "                    else:\n",
    "                        break\n",
    "                reference_values[i] = np.max(channel) if len(channel) > 0 else 255\n",
    "\n",
    "    elif method == 'robust_max':\n",
    "        reference_values = []\n",
    "        for i in range(3):\n",
    "            channel = img_float[:, :, i]\n",
    "            mean_val = np.mean(channel)\n",
    "            std_val = np.std(channel)\n",
    "\n",
    "            if std_val < 10:\n",
    "                reference_values.append(np.percentile(channel, 99))\n",
    "            elif std_val > 50:\n",
    "                reference_values.append(mean_val + 2.0 * std_val)\n",
    "            else:\n",
    "                reference_values.append(mean_val + 1.5 * std_val)\n",
    "        reference_values = np.array(reference_values)\n",
    "\n",
    "    reference_values = np.clip(reference_values, 1, 254)\n",
    "    correction_factors = 255.0 / reference_values\n",
    "    corrected_img = img_float * correction_factors\n",
    "    corrected_img = np.clip(corrected_img, 0, 255).astype(np.uint8)\n",
    "    return corrected_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff64d372",
   "metadata": {},
   "source": [
    "## 3. Algoritmo White Patch Adaptativo\n",
    "\n",
    "Selecciona automáticamente el mejor método según las características de la imagen.\n",
    "Se construyó una variante que primero clasifica la imagen usando la media y la desviación estándar del brillo y la saturación, y luego aplica el método más conveniente según esa clase. A simple vista los resultados son correctos, aunque no afirmaría que superen a los de las versiones previas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985dbb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch_adaptive(img: np.ndarray):\n",
    "    img_float = img.astype(np.float32)\n",
    "    mean_brightness = np.mean(img_float)\n",
    "    std_brightness = np.std(img_float)\n",
    "    saturated_pixels = np.sum(img_float > 250) / img_float.size\n",
    "\n",
    "    if saturated_pixels > 0.01:\n",
    "        method = 'iterative'\n",
    "    elif std_brightness < 20:\n",
    "        method = 'percentile'\n",
    "    elif mean_brightness < 80:\n",
    "        method = 'robust_max'\n",
    "    else:\n",
    "        method = 'edge_based'\n",
    "\n",
    "    return white_patch_intelligent(img, method=method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a7628",
   "metadata": {},
   "source": [
    "## 4. Procesamiento de Imágenes\n",
    "\n",
    "Procesamiento de todas las imágenes del directorio white_patch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMG_FOLDERS = Path(\"Material_TPs/TP1/white_patch\")\n",
    "RESULTS_FOLDER = Path(\"results\")\n",
    "RESULTS_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "def process_and_display_images():\n",
    "    image_paths = list(BASE_IMG_FOLDERS.glob(\"*.png\")) + list(BASE_IMG_FOLDERS.glob(\"*.jpg\"))\n",
    "    \n",
    "    for img_path in image_paths:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        corrected_img = white_patch_adaptive(img.copy())\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        corrected_rgb = cv2.cvtColor(corrected_img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        axes[0].imshow(img_rgb)\n",
    "        axes[0].set_title(f\"Original: {img_path.name}\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(corrected_rgb)\n",
    "        axes[1].set_title(f\"White Patch: {img_path.name}\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        result_filename = RESULTS_FOLDER / f\"{img_path.stem}_comparison.png\"\n",
    "        plt.savefig(result_filename, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d7de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_display_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd53f9e",
   "metadata": {},
   "source": [
    "## 5. Análisis de Histogramas\n",
    "\n",
    "Análisis de histogramas como característica para clasificación de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ade52",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMG_1 = \"Material_TPs/TP1/img1_tp.png\"\n",
    "PATH_IMG_2 = \"Material_TPs/TP1/img2_tp.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48def9c2",
   "metadata": {},
   "source": [
    "### Carga de imágenes y cálculo de histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = cv2.imread(PATH_IMG_1, cv2.IMREAD_GRAYSCALE)\n",
    "img_2 = cv2.imread(PATH_IMG_2, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "hist_1, bins_1 = np.histogram(img_1.ravel(), 255)\n",
    "hist_2, bins_2 = np.histogram(img_2.ravel(), 255)\n",
    "\n",
    "histograms_identical = np.array_equal(hist_1, hist_2)\n",
    "print(f\"Histogramas idénticos: {histograms_identical}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac2cc2",
   "metadata": {},
   "source": [
    "### Visualización comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78253be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1 = plt.figure(figsize=(15, 10))\n",
    "\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "ax1.imshow(img_1, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title(\"Imagen 1 - Degradado\")\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "ax2.imshow(img_2, cmap='gray', vmin=0, vmax=255)\n",
    "ax2.set_title(\"Imagen 2 - Flor\")\n",
    "ax2.axis('off')\n",
    "\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.plot(hist_1, color='blue', linewidth=2)\n",
    "ax3.set_title(\"Histograma Imagen 1\")\n",
    "ax3.set_xlabel(\"Intensidad\")\n",
    "ax3.set_ylabel(\"Frecuencia\")\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "ax4.plot(hist_2, color='red', linewidth=2)\n",
    "ax4.set_title(\"Histograma Imagen 2\")\n",
    "ax4.set_xlabel(\"Intensidad\")\n",
    "ax4.set_ylabel(\"Frecuencia\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"results/histogramas.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a1f034",
   "metadata": {},
   "source": [
    "### Análisis estadístico\n",
    "\n",
    "Respecto a si conviene emplear histogramas como características para clasificar imágenes, la respuesta es que es posible utilizarlos, pero hay que considerar que en un histograma se descarta toda la información espacial. Es decir, pueden existir dos imágenes con idéntico histograma y contenidos totalmente distintos.\n",
    "\n",
    "No lo recomendaría para tareas de clasificación de imágenes, ya que existen enfoques que preservan mejor la estructura espacial, como la convolución con filtros. Estos permiten capturar patrones locales y detalles relevantes, fundamentales para clasificar.\n",
    "\n",
    "Este es un contrajemplo contundente: el histograma de una imagen no la representa de forma unívoca. Usarlo como feature en un algoritmo de clasificación/detección puede ser válido, pero requiere verificación cuidadosa, porque pueden darse casos en los que dos imágenes completamente diferentes compartan el mismo histograma o uno muy similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1049bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Imagen 1 (Degradado):\")\n",
    "print(f\"Media: {np.mean(img_1):.2f}\")\n",
    "print(f\"Desviación estándar: {np.std(img_1):.2f}\")\n",
    "print(f\"Min: {np.min(img_1)}, Max: {np.max(img_1)}\")\n",
    "\n",
    "print(\"\\nImagen 2 (Flor):\")\n",
    "print(f\"Media: {np.mean(img_2):.2f}\")\n",
    "print(f\"Desviación estándar: {np.std(img_2):.2f}\")\n",
    "print(f\"Min: {np.min(img_2)}, Max: {np.max(img_2)}\")\n",
    "\n",
    "differences = np.abs(hist_1 - hist_2)\n",
    "total_diff = np.sum(differences)\n",
    "\n",
    "print(f\"\\nDiferencia total en histogramas: {total_diff}\")\n",
    "print(f\"Histogramas idénticos: {'Sí' if total_diff == 0 else 'No'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
